{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "t5_large_textqgen.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "T-sBMt823LXj",
        "myzdH1lw3HWY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-np2P_Q_08LC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import jsonlines\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, T5Config, get_linear_schedule_with_warmup, AdamW\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import time\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ddo4pus1B7Y"
      },
      "source": [
        "train_bool_df = pd.read_json('./BoolQ/train.jsonl', lines=True)\n",
        "val_bool_df = pd.read_json('./BoolQ/val.jsonl', lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSpuRFA61h5I"
      },
      "source": [
        "bool_df_all = train_bool_df.append(val_bool_df)\n",
        "bool_df_all = bool_df_all.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsWFjW3T1UqO"
      },
      "source": [
        "true_df = bool_df_all[bool_df_all.label==True]\n",
        "true_df = true_df.sample(frac=1).reset_index(drop=True).head(5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8caU99611UjX"
      },
      "source": [
        "false_df = bool_df_all[bool_df_all.label==False]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K71v66mn1Uny"
      },
      "source": [
        "bool_req = true_df.append(false_df)\n",
        "bool_req = bool_req.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jK6ckCt1Ulx"
      },
      "source": [
        "squad_full = pd.read_csv('./SQuAD_csv.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iX1Mqjc1UhO"
      },
      "source": [
        "squad_full = squad_full.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFZryFbK1UfH"
      },
      "source": [
        "squad_req = squad_full.head(10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2XCxvtS2EDl"
      },
      "source": [
        "squad_req = squad_req.drop([\"Unnamed: 0\",\"id\",\"answer_start\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GrvE5Wf2EBY"
      },
      "source": [
        "t5_tok = T5Tokenizer.from_pretrained(\"t5-large\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-sBMt823LXj"
      },
      "source": [
        "### boolq prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9WSJOqp2D_N"
      },
      "source": [
        "def input_target_text_boolq(df):\n",
        "\n",
        "    prefix = 'boolqgen'\n",
        "    \n",
        "    input_text_arr = []\n",
        "    target_text_arr = []\n",
        "    \n",
        "    for i in df.index:\n",
        "        input_text_arr.append(prefix + ' answer: ' + df.label[i]+ ' context: ' + df.passage[i])\n",
        "        target_text_arr.append(df.question[i] + '?')\n",
        "        \n",
        "    return(input_text_arr, target_text_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCgdR35q2D8g"
      },
      "source": [
        "bool_input_text, bool_target_text = input_target_text_boolq(bool_req)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5TSj3Pb2D52"
      },
      "source": [
        "bool_df = pd.DataFrame(list(zip(bool_input_text, bool_target_text)), columns = ['input_text', 'target_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuNsO-nL2D3d"
      },
      "source": [
        "bool_inp_text = bool_df.input_text.values\n",
        "bool_target_text = bool_df.target_text.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGUdUDF22Dxw"
      },
      "source": [
        "bool_inp_ids = []\n",
        "bool_inp_att_mask = []\n",
        "for ctx in tqdm_notebook(bool_inp_text):\n",
        "    tok = t5_tok.encode_plus(ctx, max_length = 512, truncation = True, \n",
        "                             return_tensors = 'pt', return_token_type_ids = False, padding = 'max_length',\n",
        "                             return_attention_mask = True, add_special_tokens = True)\n",
        "    bool_inp_ids.append(tok.input_ids)\n",
        "    bool_inp_att_mask.append(tok.attention_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsJW9xfi2DvP"
      },
      "source": [
        "bool_target_ids = []\n",
        "bool_target_att_mask = []\n",
        "for ctx in tqdm_notebook(bool_target_text):\n",
        "    tok = t5_tok.encode_plus(ctx, max_length = 32, truncation = True, \n",
        "                             return_tensors = 'pt', return_token_type_ids = False, padding = 'max_length',\n",
        "                             return_attention_mask = True, add_special_tokens = True)\n",
        "    bool_target_ids.append(tok.input_ids)\n",
        "    bool_target_att_mask.append(tok.attention_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzTjHpsE29bA"
      },
      "source": [
        "bool_inp_ids = torch.cat(bool_inp_ids, dim=0)\n",
        "bool_inp_att_mask = torch.cat(bool_inp_att_mask, dim=0)\n",
        "bool_target_ids = torch.cat(bool_target_ids, dim=0)\n",
        "bool_target_att_mask = torch.cat(bool_target_att_mask, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPmzC_cx29Y2"
      },
      "source": [
        "bool_tensor_dataset = torch.utils.data.TensorDataset(bool_inp_ids, bool_inp_att_mask, bool_target_ids, bool_target_att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAC-PiQc29WZ"
      },
      "source": [
        "train_size = int(len(bool_tensor_dataset)*.95)\n",
        "val_size = len(bool_tensor_dataset) - train_size\n",
        "\n",
        "bool_train_dataset, bool_val_dataset = torch.utils.data.random_split(bool_tensor_dataset, [train_size, val_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myzdH1lw3HWY"
      },
      "source": [
        "### squad prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kulN6wfb29Tr"
      },
      "source": [
        "def input_target_text_squad(df):\n",
        "\n",
        "    prefix = 'qgen'\n",
        "    \n",
        "    input_text_arr = []\n",
        "    target_text_arr = []\n",
        "    \n",
        "    for i in df.index:\n",
        "        inp_model = f\"{prefix} answer: {df.text[i]} context: {df.context[i]}\"\n",
        "        input_text_arr.append(inp_model)\n",
        "        target_text_arr.append(df.question[i])\n",
        "        \n",
        "    return(input_text_arr, target_text_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqrZdX-_29Ru"
      },
      "source": [
        "squad_input_text, squad_target_text = input_target_text_squad(squad_req)\n",
        "squad_df = pd.DataFrame(list(zip(squad_input_text, squad_target_text)), columns = ['input_text', 'target_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXzeU9VH29PJ"
      },
      "source": [
        "squad_inp_text = squad_df.input_text.values\n",
        "squad_target_text = squad_df.target_text.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvHPynN13SPm"
      },
      "source": [
        "squad_inp_ids = []\n",
        "squad_inp_att_mask = []\n",
        "for ctx in tqdm_notebook(squad_inp_text):\n",
        "    tok = t5_tok.encode_plus(ctx, max_length = 512, truncation = True, \n",
        "                             return_tensors = 'pt', return_token_type_ids = False, padding = 'max_length',\n",
        "                             return_attention_mask = True, add_special_tokens = True)\n",
        "    squad_inp_ids.append(tok.input_ids)\n",
        "    squad_inp_att_mask.append(tok.attention_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df1ywILi3SNU"
      },
      "source": [
        "squad_target_ids = []\n",
        "squad_target_att_mask = []\n",
        "for ctx in tqdm_notebook(squad_target_text):\n",
        "    tok = t5_tok.encode_plus(ctx, max_length = 32, truncation = True, \n",
        "                             return_tensors = 'pt', return_token_type_ids = False, padding = 'max_length',\n",
        "                             return_attention_mask = True, add_special_tokens = True)\n",
        "    squad_target_ids.append(tok.input_ids)\n",
        "    squad_target_att_mask.append(tok.attention_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yB7OZYs3DLM"
      },
      "source": [
        "squad_inp_ids = torch.cat(squad_inp_ids, dim=0)\n",
        "squad_inp_att_mask = torch.cat(squad_inp_att_mask, dim=0)\n",
        "squad_target_ids = torch.cat(squad_target_ids, dim=0)\n",
        "squad_target_att_mask = torch.cat(squad_target_att_mask, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUyBJ_IF3DI1"
      },
      "source": [
        "squad_tensor_dataset = torch.utils.data.TensorDataset(squad_inp_ids, squad_inp_att_mask, squad_target_ids, squad_target_att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaSXFe2n3DGW"
      },
      "source": [
        "train_size = int(len(squad_tensor_dataset)*.95)\n",
        "val_size = len(squad_tensor_dataset) - train_size\n",
        "\n",
        "squad_train_dataset, squad_val_dataset = torch.utils.data.random_split(squad_tensor_dataset, [train_size, val_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guuR6dc53ehe"
      },
      "source": [
        "### modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntMafrs13dB2"
      },
      "source": [
        "train_dataset = bool_train_dataset+boolans_train_dataset+squad_train_dataset\n",
        "val_dataset = bool_val_dataset+boolans_val_dataset+squad_val_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upZ3Fcdp3c89"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, sampler = torch.utils.data.RandomSampler(train_dataset),\n",
        "                                      batch_size = BATCH_SIZE)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, sampler = torch.utils.data.SequentialSampler(val_dataset),\n",
        "                                     batch_size = BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JywvXuS83c39"
      },
      "source": [
        "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-large\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is4Mb5kt3czT"
      },
      "source": [
        "t5_model.parallelize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTBe2-9s3cdJ"
      },
      "source": [
        "optimizer = AdamW(t5_model.parameters(), lr=5e-5, eps=1e-8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG7avqy83DEf"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "total_steps = len(train_loader)*EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0BfxHw43DBY"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t8KmpLx3C-a"
      },
      "source": [
        "torch.cuda.manual_seed_all(42)\n",
        "\n",
        "\n",
        "t0 = time.time()\n",
        "t5_prefixed_training_stats = []\n",
        "best_prefixed_accuracy = 0\n",
        "\n",
        "for epoch in tqdm_notebook(range(EPOCHS)):\n",
        "    \n",
        "    print(\"============ EPOCH {} / {} ===========\".format(epoch+1, EPOCHS))\n",
        "    \n",
        "    #================TRAINING=================#\n",
        "    \n",
        "    print('....TRAINING....')\n",
        "    \n",
        "    # tracking variables..\n",
        "    total_prefixed_train_loss = 0\n",
        "    total_prefixed_train_accuracy = 0\n",
        "    \n",
        "    # set to trian mode because some layers like dropout and batchnorm behave differently..\n",
        "    t5_model.train()\n",
        "    \n",
        "    for nth_batch, batch in enumerate(train_loader):\n",
        "        # logging the progress..\n",
        "        if (nth_batch+1)%500 == 0 and not nth_batch == 0:\n",
        "            elapsed = format_time(time.time()-t0)\n",
        "            print(\"\\nProcessed {} of {} batches\".format(nth_batch+1, len(train_loader)))\n",
        "        \n",
        "        # attributes to be passed..\n",
        "        prefixed_inp_ids = batch[0].to('cuda:0')\n",
        "        prefixed_inp_mask = batch[1].to('cuda:0')\n",
        "        labels = batch[2].to('cuda:0')\n",
        "        \n",
        "        # clear previously calculated gradients..\n",
        "        t5_model.zero_grad()\n",
        "        \n",
        "        # forward pass..\n",
        "        train_out = t5_model(input_ids = prefixed_inp_ids,\n",
        "                                      attention_mask = prefixed_inp_mask,\n",
        "                                      labels = labels)\n",
        "        loss = train_out.loss\n",
        "        logits = train_out.logits   # size (batch_size, max_label_length, vocab_size)\n",
        "        \n",
        "        # adding to total loss..\n",
        "        total_prefixed_train_loss += loss.item()  # '.item()' gives value from tensor\n",
        "        \n",
        "        # backward pass to calculate gradients..\n",
        "        loss.backward()\n",
        "        \n",
        "        # clipping norm of gradients to '1' to prevent exploding gradients problem..\n",
        "        torch.nn.utils.clip_grad_norm_(t5_model.parameters(), 1.0)  # '_' is inplace operator\n",
        "        \n",
        "        # update parameters and take a step using computed gradient..\n",
        "        optimizer.step()\n",
        "        \n",
        "        # update learning rate..\n",
        "        scheduler.step()\n",
        "        \n",
        "    # average out total loss..\n",
        "    prefixed_avg_train_loss = total_prefixed_train_loss / len(train_loader)\n",
        "    \n",
        "    # total train time..\n",
        "    total_prefixed_train_time = format_time(time.time()-t0)\n",
        "    \n",
        "    print(\"\\n>>>>>Average training loss {}\".format(str(prefixed_avg_train_loss)))\n",
        "    print(\"\\n>>>>>Training epoch took {}\".format(total_prefixed_train_time))\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #===============VALIDATING================#\n",
        "    \n",
        "    print(\"\\n.....VALIDATING......\")\n",
        "    \n",
        "    t0 = time.time()\n",
        "    \n",
        "    # set to eval mode because some layers like dropout and batchnorm behave differently..\n",
        "    t5_model.eval()\n",
        "    \n",
        "    # tracking variables..\n",
        "    total_prefixed_eval_accuracy = 0\n",
        "    total_prefixed_eval_loss = 0\n",
        "    nb_prefixed_eval_steps = 0\n",
        "    \n",
        "    for nth_batch, batch in enumerate(val_loader):\n",
        "        # logging the progress..\n",
        "        if (nth_batch+1)%30 == 0 and not nth_batch == 0:\n",
        "            elapsed = format_time(time.time()-t0)\n",
        "            print(\"\\nProcessed {} of {} batches\".format(nth_batch+1, len(val_loader)))\n",
        "        \n",
        "        # attributes to be passed..\n",
        "        prefixed_inp_ids_val = batch[0].to('cuda:0')\n",
        "        prefixed_inp_mask_val = batch[1].to('cuda:0')\n",
        "        labels_val = batch[2].to('cuda:0')    \n",
        "        \n",
        "        # telling pytorch not to worry about constructing computational graph during training which is used while backprop\n",
        "        with torch.no_grad():\n",
        "            val_out = t5_model(input_ids = prefixed_inp_ids_val,\n",
        "                                        attention_mask = prefixed_inp_mask_val,\n",
        "                                       labels = labels_val)\n",
        "            loss = val_out.loss\n",
        "            logits = val_out.logits\n",
        "        \n",
        "        total_prefixed_eval_loss += loss.item()\n",
        "        \n",
        "        qgen(logits.detach().cpu(), labels_val.detach().cpu())\n",
        "        \n",
        "    prefixed_avg_val_loss = total_prefixed_eval_loss / len(val_loader)\n",
        "    \n",
        "#     prefixed_avg_val_accuracy = total_prefixed_eval_accuracy / len(val_loader)\n",
        "\n",
        "    # total train time..\n",
        "    total_prefixed_val_time = format_time(time.time()-t0)\n",
        "    \n",
        "    print(\"\\n>>>>>Average validation loss {}\".format(str(prefixed_avg_val_loss)))\n",
        "    print(\"\\n Validation epoch took {}\".format(total_prefixed_val_time))    \n",
        "    \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCGLLd2W3C72"
      },
      "source": [
        "t5_model.deparallelize()\n",
        "t5_model.to('cpu')\n",
        "t5_model.save_pretrained('text_qgen')\n",
        "t5_tok.save_pretrained('text_qgen')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvhsWZDp3C48"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}